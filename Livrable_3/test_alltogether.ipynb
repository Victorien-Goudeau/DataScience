{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import collections\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIVRABLE 1 --------------------------------------------\n",
    "imgpath = \"D:\\Download\\Colors_Benalla.png\"\n",
    "\n",
    "def load_image_binary(path):\n",
    "        try:\n",
    "            image = tf.io.read_file(path)\n",
    "            image = tf.image.decode_jpeg(image, channels=3)\n",
    "            image = tf.image.resize(image, [400, 400])\n",
    "            print(type(image))\n",
    "            return tf.convert_to_tensor(image)\n",
    "        except tf.errors.InvalidArgumentError:\n",
    "            print(f\" \\n Attention : le fichier {path} n'est pas une image valide et sera ignoré.\")\n",
    "            return None\n",
    "#----------------------------------------------------\n",
    "\n",
    "#LIVRABLE3 Preprocess functions\n",
    "max_length = 33\n",
    "attention_features_shape = 64\n",
    "\n",
    "#inceptionV3---------\n",
    "image_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet')\n",
    "new_input = image_model.input\n",
    "hidden_layer = image_model.layers[-1].output\n",
    "image_features_extract_model =  tf.keras.Model(new_input, hidden_layer)\n",
    "#--------------------\n",
    "\n",
    "def load_image_captioning(image):\n",
    "    \"\"\"\n",
    "    La fonction load_image a pour entrée le chemin d'une image et pour sortie un couple\n",
    "    contenant l'image traitée ainsi que son chemin d'accès.\n",
    "    La fonction load_image effectue les traitement suivant:\n",
    "        1. Chargement du fichier correspondant au chemin d'accès image_path\n",
    "        2. Décodage de l'image en RGB.\n",
    "        3. Redimensionnement de l'image en taille (299, 299).\n",
    "        4. Normalisation des pîxels de l'image entre -1 et 1\n",
    "    \"\"\"\n",
    "    img = tf.image.decode_image(image, channels=3)\n",
    "    img = tf.image.resize(img, (299, 299))\n",
    "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img = load_image_binary(imgpath)\n",
    "img = tf.reshape(img, [1,400,400,3])\n",
    "#--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model loading\n",
    "#L1------\n",
    "model_binary = tf.keras.models.load_model('../Livrable_1/models/12_4_2024_14h58.keras')\n",
    "\n",
    "#L2------\n",
    "model_denoising_path = \"../Livrable_2/best_model/17_4_2024_17h12.keras\"\n",
    "model_denoising = tf.keras.models.load_model(model_denoising_path)\n",
    "\n",
    "#L3------\n",
    "captioning_model_path = \"./models/24_4_2024_16h17\"\n",
    "\n",
    "captioning_encoder = tf.keras.models.load_model(f\"{captioning_model_path}/encoder.tf\") #CHANGEZ ICI\n",
    "\n",
    "units = 512 # Taille de la couche caché dans le RNN\n",
    "captioning_decoder = tf.keras.models.load_model(f\"{captioning_model_path}/decoder.tf\") #CHANGEZ ICI\n",
    "\n",
    "def reset_state(batch_size):\n",
    "        return tf.zeros((batch_size, units))\n",
    "\n",
    "# tokenizer loading\n",
    "with open(f'{captioning_model_path}/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "\n",
    "def captioning(image):\n",
    "    hidden = reset_state(batch_size=1)\n",
    "\n",
    "    temp_input = tf.expand_dims(load_image_captioning(image)[0], 0)\n",
    "    img_tensor_val = image_features_extract_model(temp_input)\n",
    "    img_tensor_val = tf.reshape(img_tensor_val, (img_tensor_val.shape[0], -1, img_tensor_val.shape[3]))\n",
    "\n",
    "    features = captioning_encoder(img_tensor_val)\n",
    "\n",
    "    dec_input = tf.expand_dims([tokenizer.word_index['<start>']], 0)\n",
    "    result = []\n",
    "\n",
    "    for i in range(max_length):\n",
    "        predictions, hidden, attention_weights = captioning_decoder(dec_input, features, hidden)\n",
    "\n",
    "\n",
    "        # Reshape predictions to be a 2D matrix of shape [batch_size, vocab_size]\n",
    "        predictions = tf.reshape(predictions, [1, -1])\n",
    "\n",
    "        predicted_id = tf.random.categorical(predictions, 1)[0][0].numpy()\n",
    "        result.append(tokenizer.index_word[predicted_id])\n",
    "\n",
    "        if tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result\n",
    "\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result\n",
    "#----------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_predict = model_binary.predict(img)\n",
    "\n",
    "if binary_predict.argmax() == 1: #a changer le .value ca doit pas etre ca\n",
    "    denoised_img = model_denoising.predict(img)\n",
    "\n",
    "    caption = ' '.join(captioning(denoised_img))\n",
    "    print(caption)\n",
    "else:\n",
    "    print(\"not a picture\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
